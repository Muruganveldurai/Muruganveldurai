{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00436b53",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import pandas as pd \n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import (accuracy_score, log_loss, classification_report)\n",
    "from imblearn.over_sampling import SMOTE\n",
    "import xgboost\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc1ec4a3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f249e32f",
   "metadata": {},
   "outputs": [],
   "source": [
    "attrition = pd.read_csv('WA_Fn-UseC_-HR-Employee-Attrition.csv')\n",
    "attrition.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7daaee1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "display(attrition.isnull().any())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "623308ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "target_map = {'Yes':1, 'No':0}\n",
    "attrition[\"Attrition_numerical\"] = attrition[\"Attrition\"].apply(lambda x: target_map[x])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e86471f",
   "metadata": {},
   "outputs": [],
   "source": [
    "numerical = ['Age', 'DailyRate', 'DistanceFromHome', \n",
    "             'Education', 'EmployeeNumber', 'EnvironmentSatisfaction',\n",
    "             'HourlyRate', 'JobInvolvement', 'JobLevel', 'JobSatisfaction',\n",
    "            'MonthlyIncome', 'MonthlyRate', 'NumCompaniesWorked',\n",
    "             'PercentSalaryHike', 'PerformanceRating', 'RelationshipSatisfaction',\n",
    "             'StockOptionLevel', 'TotalWorkingYears',\n",
    "             'TrainingTimesLastYear', 'WorkLifeBalance', 'YearsAtCompany',\n",
    "             'YearsInCurrentRole', 'YearsSinceLastPromotion','YearsWithCurrManager']\n",
    "correlation_matrix = attrition[numerical].astype(float).corr()\n",
    "plt.figure(figsize=(30, 20))\n",
    "fig = sns.heatmap(correlation_matrix,annot=True)\n",
    "fig.set(xlabel='',ylabel='')\n",
    "fig.xaxis.tick_top()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9de961f",
   "metadata": {},
   "outputs": [],
   "source": [
    "numerical = ['Age', 'DailyRate',  'JobSatisfaction',\n",
    "       'MonthlyIncome', 'PerformanceRating',\n",
    "        'WorkLifeBalance', 'YearsAtCompany', 'Attrition_numerical']\n",
    "\n",
    "g = sns.pairplot(attrition[numerical], hue='Attrition_numerical', palette='seismic', diag_kind = 'kde',diag_kws=dict(shade=True))\n",
    "g.set(xticklabels=[])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad3a0261",
   "metadata": {},
   "outputs": [],
   "source": [
    "attrition = attrition.drop(['Attrition_numerical'], axis=1)\n",
    "\n",
    "# Empty list to store columns with categorical data\n",
    "categorical = []\n",
    "for col, value in attrition.iteritems():\n",
    "    if value.dtype == 'object':\n",
    "        categorical.append(col)\n",
    "\n",
    "# Store the numerical columns in a list numerical\n",
    "numerical = attrition.columns.difference(categorical)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3684d50",
   "metadata": {},
   "outputs": [],
   "source": [
    "attrition_cat = attrition[categorical]\n",
    "attrition_cat = attrition_cat.drop(['Attrition'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d4ff1f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "attrition_cat = pd.get_dummies(attrition_cat)\n",
    "attrition_cat.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0326897f",
   "metadata": {},
   "outputs": [],
   "source": [
    "attrition_num = attrition[numerical]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6df7dbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "attrition_final = pd.concat([attrition_num, attrition_cat], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a583f6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "target_map = {'Yes':1, 'No':0}\n",
    "# Use the pandas apply method to numerically encode our attrition target variable\n",
    "target = attrition[\"Attrition\"].apply(lambda x: target_map[x])\n",
    "target.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e23972b",
   "metadata": {},
   "outputs": [],
   "source": [
    "attrition['Attrition'].value_counts().plot(kind='bar')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e75898da",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cross_validation import train_test_split\n",
    "from sklearn.cross_validation import StratifiedShuffleSplit\n",
    "\n",
    "# Split data into train and test sets as well as for validation and testing\n",
    "train, test, target_train, target_val = train_test_split(attrition_final, \n",
    "                                                         target, \n",
    "                                                         train_size= 0.80,\n",
    "                                                         random_state=0);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91fd8572",
   "metadata": {},
   "outputs": [],
   "source": [
    "oversampler=SMOTE(random_state=0)\n",
    "smote_train, smote_target = oversampler.fit_sample(train,target_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b7a06e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "seed = 0   # We set our random seed to zero for reproducibility\n",
    "# Random Forest parameters\n",
    "rf_params = {\n",
    "    'n_jobs': -1,\n",
    "    'n_estimators': 1000,\n",
    "#     'warm_start': True, \n",
    "    'max_features': 0.3,\n",
    "    'max_depth': 4,\n",
    "    'min_samples_leaf': 2,\n",
    "    'max_features' : 'sqrt',\n",
    "    'random_state' : seed,\n",
    "    'verbose': 0\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a50c5d67",
   "metadata": {},
   "outputs": [],
   "source": [
    "rf = RandomForestClassifier(**rf_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d8fb873",
   "metadata": {},
   "outputs": [],
   "source": [
    "rf.fit(smote_train, smote_target)\n",
    "print(\"Fitting of Random Forest finished\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e42fc86",
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_predictions = rf.predict(test)\n",
    "print(\"Predictions finished\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7be871bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Accuracy score: {}\".format(accuracy_score(target_val, rf_predictions)))\n",
    "print(\"=\"*80)\n",
    "print(classification_report(target_val, rf_predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1df8edb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "confusion = confusion_matrix(target_val, rf_predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b72da44a",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(confusion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9db4d3a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(confusion[0][0]/(confusion[0][0]+confusion[0][1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1e8adb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_importance_df = pd.DataFrame({'Feature': attrition_final.columns, 'Importance': rf.feature_importances_})\n",
    "\n",
    "# Sort the DataFrame by feature importance in descending order\n",
    "feature_importance_df = feature_importance_df.sort_values(by='Importance', ascending=False)\n",
    "\n",
    "# Create a barplot using Seaborn\n",
    "plt.figure(figsize=(20, 35))\n",
    "sns.barplot(x='Importance', y='Feature', data=feature_importance_df, palette=\"viridis\")\n",
    "\n",
    "plt.title('Random Forest Feature Importance')\n",
    "plt.xlabel('Feature Importance')\n",
    "plt.ylabel('Feature')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "232a21a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import tree\n",
    "from IPython.display import Image as PImage\n",
    "from subprocess import check_call\n",
    "from PIL import Image, ImageDraw, ImageFont\n",
    "import re\n",
    "\n",
    "decision_tree = tree.DecisionTreeClassifier(max_depth = 4)\n",
    "decision_tree.fit(train, target_train)\n",
    "\n",
    "# Predicting results for test dataset\n",
    "y_pred = decision_tree.predict(test)\n",
    "\n",
    "# Export our trained model as a .dot file\n",
    "with open(\"tree1.dot\", 'w') as f:\n",
    "     f = tree.export_graphviz(decision_tree,\n",
    "                              out_file=f,\n",
    "                              max_depth = 4,\n",
    "                              impurity = False,\n",
    "                              feature_names = attrition_final.columns.values,\n",
    "                              class_names = ['No', 'Yes'],\n",
    "                              rounded = True,\n",
    "                              filled= True )\n",
    "        \n",
    "#Convert .dot to .png to allow display in web notebook\n",
    "check_call(['dot','-Tpng','tree1.dot','-o','tree1.png'])\n",
    "\n",
    "# Annotating chart with PIL\n",
    "img = Image.open(\"tree1.png\")\n",
    "draw = ImageDraw.Draw(img)\n",
    "img.save('sample-out.png')\n",
    "PImage(\"sample-out.png\", height=2000, width=1900)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aff44d56",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9fc6613",
   "metadata": {},
   "outputs": [],
   "source": [
    "gb_params ={\n",
    "    'n_estimators': 1500,\n",
    "    'max_features': 0.9,\n",
    "    'learning_rate' : 0.25,\n",
    "    'max_depth': 4,\n",
    "    'min_samples_leaf': 2,\n",
    "    'subsample': 1,\n",
    "    'max_features' : 'sqrt',\n",
    "    'random_state' : seed,\n",
    "    'verbose': 0\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5aae2ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "gb = GradientBoostingClassifier(**gb_params)\n",
    "# Fit the model to our SMOTEd train and target\n",
    "gb.fit(smote_train, smote_target)\n",
    "# Get our predictions\n",
    "gb_predictions = gb.predict(test)\n",
    "print(\"Predictions have finished\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f0baaa6",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(accuracy_score(target_val, gb_predictions))\n",
    "print(classification_report(target_val, gb_predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32ff557b",
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_importance_df = pd.DataFrame({'Feature': attrition_final.columns, 'Importance': gb.feature_importances_})\n",
    "\n",
    "# Sort the DataFrame by feature importance in descending order\n",
    "feature_importance_df = feature_importance_df.sort_values(by='Importance', ascending=False)\n",
    "\n",
    "# Create a barplot using Seaborn\n",
    "plt.figure(figsize=(20,25))\n",
    "sns.barplot(x='Importance', y='Feature', data=feature_importance_df, palette=\"viridis\")\n",
    "\n",
    "plt.title('Gradient Boosting Model Feature Importance')\n",
    "plt.xlabel('Feature Importance')\n",
    "plt.ylabel('Feature')\n",
    "\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
